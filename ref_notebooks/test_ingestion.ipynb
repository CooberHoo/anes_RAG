{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02c689b-ba26-445d-a504-b176227ebeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9 pages from ../resources/miller_anes_test.pdf\n",
      "✅ Cleaned text saved to ../resources/cleaned_miller_chapter.json (9 pages)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIGURATION\n",
    "# -----------------------------\n",
    "PDF_PATH = \"../resources/miller_anes_test.pdf\"\n",
    "OUTPUT_JSON = \"../resources/cleaned_miller_chapter.json\"\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 1: LOAD PDF\n",
    "# -----------------------------\n",
    "reader = PdfReader(PDF_PATH)\n",
    "raw_pages = [page.extract_text() for page in reader.pages]\n",
    "\n",
    "# Filter out blank pages\n",
    "raw_pages = [p for p in raw_pages if p and len(p.strip()) > 20]\n",
    "print(f\"Loaded {len(raw_pages)} pages from {PDF_PATH}\")\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 2: BASIC CLEANING\n",
    "# -----------------------------\n",
    "def clean_page_text(text):\n",
    "    \"\"\"\n",
    "    Cleans one PDF page:\n",
    "    1. Removes standalone page numbers\n",
    "    2. Joins hyphenated words\n",
    "    3. Fixes single line breaks in sentences\n",
    "    4. Collapses multiple spaces/newlines\n",
    "    \"\"\"\n",
    "    # Remove standalone page numbers like \"123\" or \"- 123 -\"\n",
    "    text = re.sub(r\"\\n?\\s*-?\\s*\\d+\\s*-?\\s*\\n?\", \"\\n\", text)\n",
    "    \n",
    "    # Join hyphenated words across line breaks\n",
    "    text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n",
    "    \n",
    "    # Replace single line breaks inside paragraphs with space\n",
    "    text = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", text)\n",
    "    \n",
    "    # Collapse multiple newlines into paragraph breaks\n",
    "    text = re.sub(r\"\\n\\s*\\n+\", \"\\n\\n\", text)\n",
    "    \n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "clean_pages = [clean_page_text(p) for p in raw_pages]\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 3: REMOVE REPEATED HEADERS/FOOTERS\n",
    "# -----------------------------\n",
    "from collections import Counter\n",
    "\n",
    "# Detect repeated first/last lines (likely headers or author names)\n",
    "first_lines = [p.split(\"\\n\")[0].strip() for p in clean_pages if p]\n",
    "last_lines = [p.split(\"\\n\")[-1].strip() for p in clean_pages if p]\n",
    "\n",
    "common_headers = [h for h, c in Counter(first_lines).items() if c > 3 and len(h) > 0]\n",
    "common_footers = [f for f, c in Counter(last_lines).items() if c > 3 and len(f) > 0]\n",
    "\n",
    "def remove_headers_footers(text):\n",
    "    for h in common_headers + common_footers:\n",
    "        text = text.replace(h, \"\")\n",
    "    return text.strip()\n",
    "\n",
    "clean_pages = [remove_headers_footers(p) for p in clean_pages]\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 5: REMOVE REFERENCES SECTION\n",
    "# -----------------------------\n",
    "def remove_references(text):\n",
    "    \"\"\"\n",
    "    Removes text from 'References' to the end of the page/document.\n",
    "    \"\"\"\n",
    "    pattern = r\"(REFERENCES.*)$\"\n",
    "    cleaned_text = re.sub(pattern, \"\", text, flags=re.IGNORECASE | re.DOTALL)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "clean_pages = [remove_references(p) for p in clean_pages]\n",
    "\n",
    "#txt file saved\n",
    "full_text = \"\\n\\n\".join(clean_pages)\n",
    "with open(\"cleaned_test_chapter.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(full_text)\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 6: DETECT CHAPTER TITLES\n",
    "# -----------------------------\n",
    "chapter_pattern = re.compile(r\"(CHAPTER\\s+\\d+|[A-Z][A-Z\\s]{5,})\")\n",
    "\n",
    "def detect_chapter(page):\n",
    "    # Search in first 200 chars for heading\n",
    "    match = chapter_pattern.search(page[:200])\n",
    "    return match.group(0).strip() if match else None\n",
    "\n",
    "documents = []\n",
    "current_chapter = \"Unknown Chapter\"\n",
    "\n",
    "for i, page in enumerate(clean_pages, start=1):\n",
    "    chapter = detect_chapter(page) or current_chapter\n",
    "    if detect_chapter(page):\n",
    "        current_chapter = chapter\n",
    "\n",
    "    documents.append({\n",
    "        \"content\": page,\n",
    "        \"metadata\": {\n",
    "            \"page_number\": i,\n",
    "            \"chapter\": current_chapter,\n",
    "            \"source\": PDF_PATH\n",
    "        }\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 7: SAVE CLEANED OUTPUT\n",
    "# -----------------------------\n",
    "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(documents, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Cleaned text saved to {OUTPUT_JSON} ({len(documents)} pages)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db99ac0-abe6-4307-ad95-7d71f1db4fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (anes_rag)",
   "language": "python",
   "name": "anes_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
